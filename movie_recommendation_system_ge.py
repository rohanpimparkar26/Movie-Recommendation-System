# -*- coding: utf-8 -*-
"""Movie Recommendation System Ge

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X6v3-Vimjt-LUwh_uLcTQZZtyK4OXBUd
"""

# ----------------------------------------------------------------------------------
# Movie Recommendation System (Content-Based Filtering)
#
# This script is a complete, runnable solution for Google Colab.
# It includes the fix for the data loading/merging error.
# ----------------------------------------------------------------------------------

import pandas as pd
import numpy as np
import ast
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. DATA COLLECTION (Colab Setup) ---
print("Step 1: Data Collection (Downloading and Loading Data)...")

# Download the necessary files
!wget -q https://raw.githubusercontent.com/manoj-prabhakar/tmdb-data/master/tmdb_5000_movies.csv
!wget -q https://raw.githubusercontent.com/manoj-prabhakar/tmdb-data/master/tmdb_5000_credits.csv

# Load the datasets
try:
    movies = pd.read_csv('tmdb_5000_movies.csv')
    credits = pd.read_csv('tmdb_5000_credits.csv')

    # --- CRITICAL FIX ---
    # Rename only the 'movie_id' column to 'id' to allow for a correct merge
    credits = credits.rename(columns={'movie_id': 'id'})
    # ---------------------

    # --- Data Type Cleaning (for robust merging) ---
    movies['id'] = pd.to_numeric(movies['id'], errors='coerce')
    credits['id'] = pd.to_numeric(credits['id'], errors='coerce')

    movies = movies.dropna(subset=['id'])
    credits = credits.dropna(subset=['id'])

    movies['id'] = movies['id'].astype(int)
    credits['id'] = credits['id'].astype(int)
    # -------------------------------------------------------

    # Merge the two DataFrames on the common 'id' column
    df = movies.merge(credits, on='id')

    print(f"Data loaded successfully. Total movies in the database: {df.shape[0]}")

    if df.shape[0] == 0:
        print("ERROR: Merge resulted in 0 movies. Check column names and files.")
        exit()

except Exception as e:
    print(f"FATAL Error during data loading or merging: {e}")
    print("Recommendation system initialization aborted.")
    exit()

# --- 2. DATA PREPROCESSING & FEATURE ENGINEERING ---

# Select the features required for content-based filtering
# 'title_x' is the title from the 'movies' file after the merge
df = df[['title_x', 'genres', 'keywords', 'cast', 'crew', 'overview']]
df.columns = ['title', 'genres', 'keywords', 'cast', 'crew', 'overview']

# Fill NaN values in 'overview' with an empty string
df['overview'] = df['overview'].fillna('')
df = df.dropna()

print("\nStep 2: Data Preprocessing and Feature Extraction...")

# Helper function to safely parse stringified lists and extract names
def get_list_names(x, limit=3):
    if isinstance(x, str) and x.startswith('['):
        try:
            items = ast.literal_eval(x)
            if isinstance(items, list):
                names = [d['name'] for d in items]
                return names[:limit] if limit else names
        except (ValueError, IndexError):
            pass
    return []

# Helper function to extract the Director from the 'crew' list
def get_director(x):
    if isinstance(x, str) and x.startswith('['):
        try:
            members = ast.literal_eval(x)
            for member in members:
                if member['job'] == 'Director':
                    return [member['name']]
        except (ValueError, IndexError):
            pass
    return []

# Apply parsing and extraction functions
df['genres'] = df['genres'].apply(lambda x: get_list_names(x, limit=None))
df['keywords'] = df['keywords'].apply(lambda x: get_list_names(x, limit=None))
df['cast'] = df['cast'].apply(lambda x: get_list_names(x, limit=3))
df['director'] = df['crew'].apply(get_director)

# Cleanup function: lowercases and removes spaces (e.g., 'Chris Evans' -> 'chrisevans')
def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return [str.lower(x.replace(" ", ""))]
        return []

for col in ['genres', 'keywords', 'cast', 'director']:
    df[col] = df[col].apply(clean_data)

# Combine all processed features into the 'soup' string for vectorization
def create_soup(x):
    features = ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + ' '.join(x['director']) + ' ' + ' '.join(x['genres']) + ' ' + x['overview']
    return features

df['soup'] = df.apply(create_soup, axis=1)

print("Preprocessing complete. Combined text features into the 'soup' column.")


# --- 3. FEATURE EXTRACTION (TF-IDF Vectorizer) ---
print("\nStep 3: Applying TF-IDF Vectorization...")

# Initialize TF-IDF Vectorizer, removing common English stop words
tfidf = TfidfVectorizer(stop_words='english')

# Create the TF-IDF matrix by fitting and transforming the 'soup' data
tfidf_matrix = tfidf.fit_transform(df['soup'])

print(f"TF-IDF matrix created with shape: {tfidf_matrix.shape}")


# --- 4. MODEL BUILDING (Cosine Similarity Calculation) ---
print("\nStep 4: Calculating Cosine Similarity Matrix...")

# Calculate the cosine similarity between all movies
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(f"Cosine Similarity matrix calculated. Shape: {cosine_sim.shape}")

# Create a reverse mapping of movie titles to their index
indices = pd.Series(df.index, index=df['title']).drop_duplicates()


# --- 5. RECOMMENDATION FUNCTION ---

def recommend(title, cosine_sim=cosine_sim, df=df, indices=indices):
    """
    Generates the top 5 movie recommendations based on content similarity.
    """

    # Check if the movie exists in our database
    if title not in indices:
        print(f"\nError: Movie '{title}' not found in the database. Please check the spelling (case-sensitive).")
        # Suggest similar matches
        matches = df[df['title'].str.contains(title, case=False, na=False)]['title'].tolist()
        if matches:
            print(f"Did you mean one of these?\n{matches[:5]}")
        return []

    # Get the index of the movie that matches the title
    idx = indices[title]

    # Get the similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 6 most similar movies (index 0 is the movie itself)
    sim_scores = sim_scores[1:7]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Get the movie titles
    recommendations = df['title'].iloc[movie_indices]

    print(f"\n--- Top 5 Recommendations for '{title}' ---")

    # Print the top 5 recommendations with their scores
    results = []
    for i, movie_title in enumerate(recommendations):
        score = sim_scores[i][1]
        print(f"{i+1}. {movie_title} (Similarity: {score:.4f})")
        results.append((movie_title, score))

    return results

# --- 6. EXECUTION AND DEMONSTRATION ---

print("\n\n--- Running Demonstration Test Cases ---")
recommend('The Dark Knight Rises')
recommend('Avatar')
recommend('Interstellar')
recommend('Inception') # Another test

print("\nMovie Recommendation System execution finished successfully!")

